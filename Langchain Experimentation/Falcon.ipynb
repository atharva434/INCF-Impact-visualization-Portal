{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (0.0.216)\n",
      "Collecting einops\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "     -------------------------------------- 42.2/42.2 kB 999.8 kB/s eta 0:00:00\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
      "     -------------------------------------- 244.2/244.2 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "     ---------------------------------------- 7.2/7.2 MB 2.1 MB/s eta 0:00:00\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.40.0.post4-py3-none-any.whl (101.8 MB)\n",
      "     -------------------------------------- 101.8/101.8 MB 1.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (0.5.8)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (1.25.0)\n",
      "Requirement already satisfied: langchainplus-sdk>=0.0.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (0.0.17)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (1.10.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: psutil in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Downloading safetensors-0.3.1-cp39-cp39-win_amd64.whl (263 kB)\n",
      "     ------------------------------------ 263.9/263.9 kB 395.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.14.1\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "     ------------------------------------ 268.8/268.8 kB 720.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2022.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sandeep\\anaconda3\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.2.1)\n",
      "Installing collected packages: safetensors, bitsandbytes, einops, huggingface-hub, transformers, accelerate\n",
      "Successfully installed accelerate-0.21.0 bitsandbytes-0.40.0.post4 einops-0.6.1 huggingface-hub-0.16.4 safetensors-0.3.1 transformers-4.30.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain einops accelerate transformers bitsandbytes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\YouTube\\6-06-2023 - Falcon\\falcon\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFacePipeline\n",
    "from langchain import PromptTemplate,  LLMChain\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import os \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if cuda is available \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model ID\n",
    "model_id = \"tiiuae/falcon-40b-instruct\"\n",
    "# Load Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# Load Model \n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, cache_dir='./workspace/', \n",
    "    torch_dtype=torch.bfloat16, trust_remote_code=True, device_map=\"auto\", offload_folder=\"offload\")\n",
    "# Set PT model to inference mode\n",
    "model.eval()\n",
    "# Build HF Transformers pipeline \n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", \n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    "    max_length=400,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the pipeline\n",
    "pipeline('who is kim kardashian?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass it to Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup prompt template\n",
    "template = PromptTemplate(input_variables=['input'], template='{input}') \n",
    "# Pass hugging face pipeline to langchain class\n",
    "llm = HuggingFacePipeline(pipeline=pipeline) \n",
    "# Build stacked LLM chain i.e. prompt-formatting + LLM\n",
    "chain = LLMChain(llm=llm, prompt=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test LLMChain \n",
    "response = chain.run('who is kim kardashian?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Gradio App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Gradio for the UI component\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gradio for UI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generate function - this will be called when a user runs the gradio app \n",
    "def generate(prompt): \n",
    "    # The prompt will get passed to the LLM Chain!\n",
    "    return chain.run(prompt)\n",
    "    # And will return responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a string variable to hold the title of the app\n",
    "title = 'ü¶úüîó Falcon-40b-Instruct'\n",
    "# Define another string variable to hold the description of the app\n",
    "description = 'This application demonstrates the use of the open-source `Falcon-40b-Instruct` LLM.'\n",
    "# pls subscribe üôè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build gradio interface, define inputs and outputs...just text in this\n",
    "gr.Interface(fn=generate, inputs=[\"text\"], outputs=[\"text\"], \n",
    "             # Pass through title and description\n",
    "             title=title, description=description, \n",
    "             # Set theme and launch parameters\n",
    "             theme='finlaymacklon/boxy_violet').launch(server_port=8080, share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "falcon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
